---
title: "Power and Sample Size Calculation"
author: "Jingyang(Judy) Zhang"
date: "10/6/2021"
output: html_document
---


# A. Problem Setup

Test whether there is a significant difference among variances of k groups. For example, if k = 2, the problem can be to test whether there is a significant difference between the variance of treatment group and the variance of control group. 


# B. Setup

$x_{ij}$:$j^{th}$ observation in $i^{th}$ group.$i\in{1,2,3,…,n_i}$ where $n_i$  is the sample size of the $i^{th}$ group.

$i\in{1,2,…,k}$: number of groups.

$N = \sum_{i=1}^{k}n_i$∶ total number of observations of k groups. 

$σ_i^2$: population variance of the $i^{th}$ group.

$s_i^2$: sample variance of the $i^{th}$ group. 

$\bar{x}_{..} = \frac{\sum_{i=1}^{k}\sum{j=1}^{n_i}x_{ij}}{N}$: the overall mean of the N observations.

$\bar{x}_{i.} = \frac{\sum_{j=1}^{n_i}x_{ij}}{n_i}$: the group mean of the $i^{th}$ group. 

$\alpha$: significance level (also is the Type I error rate). 

$\lambda = \sum_{i=1}^{2}(\frac{\mu_i}{\sigma_i})^{2}$: the noncentrality parameter for F distribution.

Note: in R, functions pf, qf, rf, etc. define noncentrality parameter of F distribution as:

$\lambda = \sum_{i=1}^{2}(\mu_i)^2$


# C. F Test for Equality of Two Variances ($k=2$)

1. \textbf{Assumptions:}

a. Both populations are normally distributed.

b. The two populations are independent of each other. 

2. \textbf{Hypotheses:}

$H_0: \sigma_1^2 = \sigma_2^2$

$H_a: \sigma_1^2 \neq \sigma_2^2$ (Two-Tailed Test)

$H_a: \sigma_1^2 > \sigma_2^2$ (Upper One-Tailed Test)

$H_a: \sigma_1^2 < \sigma_2^2$ (Lower One-Tailed Test)


3. \textbf{Test Statistic:} 

$F = \frac{s_1^2}{s_2^2} = \frac{\frac{\sum_{j=1}^{n_1}(x_{1j} - x_{1.})^2}{n_1 -1}}{\frac{\sum_{j=1}^{n_2}(x_{2j} - x_{2.})^2}{n_2 -1}}$


4. \textbf{Rejection Region:}

Let $F_{\alpha, d_1, d_2}$ denote the lower critical value from the F distribution with $d_1$ and $d_2$ dfs and a significance level $\alpha$.

a. $F < F_{1-\frac{\alpha}{2}, n_1 - 1, n_2 - 1}$ or $F > F_{\frac{\alpha}{2}, n_1 - 1, n_2 -1}$ for two-tailed test. 

b. $F > F_{1-\alpha, n_1-1, n_2-1}$ for upper one-tailed test. 

c. $F < F_{\alpha, n_1 - 1, n_2 -1}$ for lower one-tailed test. 


5. \textbf{Power:}

Let $F_{d_1, d_2}$ be the distribution function of the F distribution with $d_1$ and $d_2$ degrees of freedom. 

Let $v_{d_1, d_2, A} = F^{-1}_{d_1, d_2}(A)$ be the inverse CDF evaluated at A for an F distribution with $d_1$ and $d_2$ dfs. 

a. Two-Tailed Test

$\lambda = 1 - F_{d_1, d_{2}}\{\frac{v_{d_1, d_2, 1-\alpha}}{(\frac{\sigma_1}{\sigma_2})^2}\} + F_{d_1, d_{2}}\{\frac{v_{d_1, d_2, \alpha}}{(\frac{\sigma_1}{\sigma_2})^2}\}$

b. Upper One-Tailed Test

$\lambda = F_{d_1, d_{2}}\{\frac{v_{d_1, d_2, 1-\alpha}}{(\frac{\sigma_1}{\sigma_2})^2}\}$ 


c. Lower One-Tailed Test

$\lambda = F_{d_1, d_{2}}\{\frac{v_{d_1, d_2, \alpha}}{(\frac{\sigma_1}{\sigma_2})^2}\}$ 






# D. Calculation

Data
```{r}

var1 <- 134.69

var2 <- 185.61

n1 <- 101

n2 <- 95

alpha <- 0.05

var_p1 <- 150.38

var_p2 <- 178.99

mu1 <- 85.9

mu2 <- 100.25

```





1. F Test for Equality of Two Population Variances

$H_0: \sigma_1^2 = \sigma_2^2$

Two-Sided Test: $H_a: \sigma_1^2 \neq \sigma_2^2$

Upper One-Sided Test: $H_a: \sigma_1^2 > \sigma_2^2$

Lower One-Sided Test: $H_a: \sigma_1^2 < \sigma_2^2$

Given: sample variances $s_1^2, s_2^2$, sample sizes $n_1, n_2$, significance level $\alpha$, test (1 = lower one-sided test; 2 = upper one-sided test; 3 = two-sided test).


```{r}

variance_test <- function(var1, var2, n1, n2, alpha, test){
  
  # Calculate observed F-stat
  F_obsved <- var1/var2
  
  
  if(test == 1){
    
     F_crit_lower <- qf(alpha, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
     
     if(F_obsved < F_crit_lower){
       
        print(paste("F Test Statistic Observed:", F_obsved, sep = " "))
        
        print(paste("F Critical Value (Lower):", F_crit_lower, sep = " "))
        
        print("Result of Lower One-Sided Test: Reject H0")
       
     }else{
       
        print(paste("F Test Statistic Observed:", F_obsved, sep = " "))
        
        print(paste("F Critical Value (Lower):", F_crit_lower, sep = " "))
        
        print("Result of Lower One-Sided Test: Fail to reject H0")
       
     }
    
    
  }
  
  
  
  
  if(test == 2){
    
    F_crit_upper <- qf(1-alpha, n1-1, n2-1,
                         lower.tail = TRUE, log.p = FALSE)
    
    if(F_obsved > F_crit_upper){
      
        print(paste("F Test Statistic Observed:", F_obsved, sep = " "))
      
        print(paste("F Critical Value (Upper):", F_crit_upper, sep = " "))
        
        print("Result of Upper One-Sided Test: Reject H0")
      
      
    }else{
      
        print(paste("F Test Statistic Observed:", F_obsved, sep = " "))
        
        print(paste("F Critical Value (Upper):", F_crit_upper, sep = " "))
        
        print("Result of Upper One-Sided Test: Fail to reject H0")
      
      
    }
    
  }
  
  
  
  if(test == 3){
    
     F_crit_lower <- qf(alpha/2, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
     
     F_crit_upper <- qf(1 - alpha/2, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
     
     if(F_obsved < F_crit_lower | F_obsved > F_crit_upper){
       
       
        print(paste("F Test Statistic Observed:", F_obsved, sep = " "))
        
        print(paste("F Critical Value (Lower):", F_crit_lower, sep = " "))
        
        print(paste("F Critical Value (Upper):", F_crit_upper, sep = " "))
        
        print("Result of Two-Sided Test: Reject H0")
       
       
     }else{
       
        print(paste("F Test Statistic Observed:", F_obsved, sep = " "))
        
        print(paste("F Critical Value (Lower):", F_crit_lower, sep = " "))
        
        print(paste("F Critical Value (Upper):", F_crit_upper, sep = " "))
        
        print("Result of Two-Sided Test: Fail to reject H0")
       
     }
  
  }
    
  
}

```


Verify:
```{r}

# Lower One-Sided Test
variance_test(var1, var2, n1, n2, alpha, 1)


# Upper One-Sided Test

variance_test(var1, var2, n1, n2, alpha, 2)


# Two-Sided Test
variance_test(var1, var2, n1, n2, alpha, 3)

```




2. Calculate Power of the F Test for Equality of Two Population Variances

Given: sample variances $s_1^2, s_2^2$, sample sizes $n_1, n_2 > 5$ (as var(F) only exists when $v_2 = n_2 -1 > 4$), significance level $\alpha$, population variances $\sigma_1^2, \sigma_2^2$, population means $\mu_1, \mu_2$,test (1 = lower one-sided test; 2 = upper one-sided test; 3 = two-sided test). 

```{r}

cal_power <- function(var1, var2, n1, n2, alpha, var_p1, var_p2, mu1, mu2, test){
  
  ncp <- (mu1)^2 + (mu2)^2
  
  if(test == 1){
    
    F_crit_lower <- qf(alpha, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
    
    power <- pf(F_crit_lower, n1-1, n2-1, ncp, 
                lower.tail =  TRUE, log.p = FALSE)
    
    print(paste("The power of the lower one-sided test is:", power, sep = " "))
  }
  
  
  if(test == 2){
    
    F_crit_upper <- qf(1 - alpha, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
    
    power <- pf(F_crit_upper, n1-1, n2-1, ncp, 
                lower.tail =  FALSE, log.p = FALSE)
    
    print(paste("The power of the upper one-sided test is:", power, sep = " "))
  }
  
  
  if(test == 3){
    
    F_crit_upper <- qf(1 - alpha/2, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
    
    power_upper <- pf(F_crit_upper, n1-1, n2-1, ncp, 
                lower.tail =  FALSE, log.p = FALSE)
    
    F_crit_lower <- qf(alpha/2, n1-1, n2-1, 
                       lower.tail = TRUE, log.p = FALSE)
    
    power_lower <- pf(F_crit_lower, n1-1, n2-1, ncp,
                        lower.tail = TRUE, log.p = FALSE)
    
    power <- power_lower + power_upper
    
    print(paste("The power of the two-sided test is:", power, sep = " "))
  }
  
}


```



Verify:
```{r}


# Lower One-Sided Test
cal_power(var1, var2, n1, n2, alpha, 
          var_p1, var_p2, mu1, mu2, 1)


# Upper One-Sided Test

cal_power(var1, var2, n1, n2, alpha, 
          var_p1, var_p2, mu1, mu2, 2)


# Two-Sided Test
cal_power(var1, var2, n1, n2, alpha, 
          var_p1, var_p2, mu1, mu2, 3)

```



3. Calculate Sample Size (assume same sample size for both treatment and control groups) for a Given Power of a F Test for Equality of Two Population Variances

Given: power $\pi$, significance level $\alpha$, population variances $\sigma_1^2, \sigma_2^2$, population means $\mu_1, \mu_2$, test (1 = lower one-sided test; 2 = upper one-sided test; 3 = two-sided test), and upper limit of $n_{upper}$ per group. 

Note: variance of noncentral F distribution with degree of freedoms df1, df2, and ncp only exists for $df_2 > 4$:


$E\{F_{df_1, df_2, \lambda}\} = \frac{df_2(df_1+\lambda)}{df_1(df_2 - 2)}$ for $df_2 > 2$

$E\{F_{df_1, df_2, \lambda}\}$ does not exist for $df_2\leq 2$


$Var\{F_{df_1, df_2, \lambda}\} = 2\frac{(df_1 + \lambda)^2 + (df_1 + 2\lambda)(df_2 - 2)}{(df_2 -2)^2(df_2 -4)}(\frac{df_2}{df_1})^2$ for $df_2 > 4$

$Var\{F_{df_1, df_2, \lambda}\}$ does not exist for $df_2 \leq 4$

```{r}

cal_sample_size <- function(p, alpha, var_p1, var_p2, mu1, mu2, test, n_upper){
  
  ncp <- (mu1)^2 + (mu2)^2
  
  if(test == 1){
    
    # Set initial sample size per group as 5
    
    n <- 5
    
    F_crit_lower <- qf(alpha, n-1, n-1, 
                       lower.tail = TRUE, log.p = FALSE)
    
    power <- pf(F_crit_lower, n-1, n-1, 
                ncp, lower.tail = TRUE, log.p = FALSE)
    
   
    
    while(n <= n_upper & power < p){
      
      n <- n + 1
      
      F_crit_lower <- qf(alpha, n-1, n-1, 
                      lower.tail = TRUE, log.p = FALSE)
    
      power <- pf(F_crit_lower, n-1, n-1, 
                ncp, lower.tail = TRUE, log.p = FALSE)
      
    }
    
  }
  
  if(power >= p){
    print(paste(paste(paste("Sample size (per group) needed to achieve the given power of", p, sep = " "), "is", sep = " "), n, sep = " "))}
  else{
    print(paste(paste(paste("Power of", p, sep = " "), "cannot be achieved with sample size (per group) less than"), n_upper, sep = " "))
    
  }
  
  
}

```




Verify:

```{r}
cal_sample_size(0.2, alpha, var_p1, var_p2, mu1, mu2, 1, 2000)
```

